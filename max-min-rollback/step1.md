# ğŸ”„ Configure and Execute Rolling Update

## ğŸ“‹ Mission Brief

The production web platform `web1` needs to be updated to a new version with **zero downtime**. You must configure strict rolling update parameters and demonstrate the ability to rollback if needed.

### ğŸ¯ Current State
- **Namespace**: `prod`
- **Deployment**: `web1`
- **Current Image**: `public.ecr.aws/nginx/nginx:perl`
- **Replicas**: 10
- **Status**: Default rolling update strategy (not suitable for production)

### ğŸ“ Task Requirements

#### Part 1: Configure Rolling Update Strategy
Update the deployment `web1` to use:
- âœ… **New Image**: `public.ecr.aws/nginx/nginx:stable-perl`
- âœ… **maxUnavailable**: `0%` (no pods can be unavailable)
- âœ… **maxSurge**: `5%` (maximum 5% extra pods during rollout)
- âœ… **Rolling Update Type**: `RollingUpdate`

#### Part 2: Execute and Monitor Rollout
- âœ… Apply the configuration changes
- âœ… Monitor the rollout progress
- âœ… Verify all pods are updated successfully

#### Part 3: Simulate Failure and Rollback
- âœ… Assume the new version has issues (CSS rendering broken)
- âœ… Execute immediate rollback to previous version
- âœ… Verify all pods are back to `perl` image
- âœ… Confirm rollback completed successfully

---

## ğŸ’¡ Try It Yourself First!

<details><summary>ğŸ“‹ Complete Solution (Click to expand)</summary>

### Step 1: Configure Rolling Update Strategy

You can use `kubectl patch` or edit the deployment directly:

**Option A: Using kubectl patch (Recommended for exam speed)**

```bash
# Update the rolling update strategy
kubectl -n prod patch deployment web1 -p '{
  "spec": {
    "strategy": {
      "type": "RollingUpdate",
      "rollingUpdate": {
        "maxUnavailable": "0%",
        "maxSurge": "5%"
      }
    }
  }
}'
```

**Option B: Using kubectl edit**

```bash
kubectl -n prod edit deployment web1
```

Then modify the `strategy` section:

```yaml
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0%
      maxSurge: 5%
```

**Option C: Apply complete YAML**

```bash
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web1
  namespace: prod
  labels:
    app: web-frontend
    tier: frontend
    environment: production
spec:
  replicas: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0%
      maxSurge: 5%
  selector:
    matchLabels:
      app: web-frontend
  template:
    metadata:
      labels:
        app: web-frontend
        tier: frontend
        version: perl
    spec:
      containers:
      - name: nginx
        image: public.ecr.aws/nginx/nginx:perl
        ports:
        - containerPort: 80
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 3
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 5
EOF
```

### Step 2: Update the Image to New Version

```bash
# Update the container image
kubectl -n prod set image deployment/web1 nginx=public.ecr.aws/nginx/nginx:stable-perl
```

**Alternative: Record the change for rollout history**

```bash
kubectl -n prod set image deployment/web1 nginx=public.ecr.aws/nginx/nginx:stable-perl --record
```

### Step 3: Monitor the Rollout

```bash
# Watch the rollout status in real-time
kubectl -n prod rollout status deployment/web1

# In another terminal, watch pods updating
kubectl -n prod get pods -l app=web-frontend -w

# Check rollout history
kubectl -n prod rollout history deployment/web1

# View detailed rollout status
kubectl -n prod describe deployment web1
```

### Step 4: Verify the Update

```bash
# Check current image version
kubectl -n prod get deployment web1 -o jsonpath='{.spec.template.spec.containers[0].image}'
echo ""

# Verify all pods are running the new image
kubectl -n prod get pods -l app=web-frontend -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[0].image}{"\n"}{end}'

# Check deployment status
kubectl -n prod get deployment web1
```

### Step 5: Simulate Failure Scenario

Assume you've discovered that the new version has CSS rendering issues affecting users.

```bash
echo "âš ï¸  ALERT: New version has CSS rendering issues!"
echo "ğŸ”§ Initiating immediate rollback..."
```

### Step 6: Execute Rollback

```bash
# Rollback to previous version
kubectl -n prod rollout undo deployment/web1

# Monitor the rollback progress
kubectl -n prod rollout status deployment/web1

# Alternative: Rollback to specific revision
# kubectl -n prod rollout undo deployment/web1 --to-revision=1
```

### Step 7: Verify Rollback Success

```bash
# Check current image after rollback
kubectl -n prod get deployment web1 -o jsonpath='{.spec.template.spec.containers[0].image}'
echo ""

# Verify all pods are back to old image
kubectl -n prod get pods -l app=web-frontend -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[0].image}{"\n"}{end}'

# Check rollout history
kubectl -n prod rollout history deployment/web1

# Verify all replicas are ready
kubectl -n prod get deployment web1
```

---

### ğŸ“Š Understanding the Configuration

**maxUnavailable: 0%**
- Ensures no pods are taken down during update
- New pods must be ready before old ones are terminated
- Guarantees zero downtime for users

**maxSurge: 5%**
- Allows maximum 5% extra pods during rollout
- For 10 replicas: 0.5 rounds up to 1 extra pod
- Controls resource usage during update

**Rollout Process with these settings:**
1. Creates 1 new pod (5% surge)
2. Waits for new pod to be ready
3. Terminates 1 old pod
4. Repeats until all pods updated

---

### âœ… Success Criteria

After completion, you should have:

1. âœ… **Deployment configured** with maxUnavailable=0%, maxSurge=5%
2. âœ… **Image updated** to `stable-perl` version
3. âœ… **Rollout completed** successfully with zero downtime
4. âœ… **Rollback executed** back to `perl` version
5. âœ… **All 10 replicas** running and ready
6. âœ… **Rollout history** showing both update and rollback revisions

---

### ğŸ” Troubleshooting Tips

If rollout gets stuck:
```bash
# Pause the rollout
kubectl -n prod rollout pause deployment/web1

# Resume the rollout
kubectl -n prod rollout resume deployment/web1

# Check pod events
kubectl -n prod get events --sort-by='.lastTimestamp'
```

If you need to check specific revision:
```bash
# View specific revision details
kubectl -n prod rollout history deployment/web1 --revision=2
```

---

### ğŸ“š Key kubectl Commands Reference

```bash
# Rollout management
kubectl rollout status deployment/web1 -n prod
kubectl rollout history deployment/web1 -n prod
kubectl rollout undo deployment/web1 -n prod
kubectl rollout pause deployment/web1 -n prod
kubectl rollout resume deployment/web1 -n prod

# Image updates
kubectl set image deployment/web1 nginx=IMAGE -n prod
kubectl set image deployment/web1 nginx=IMAGE -n prod --record

# Monitoring
kubectl get deployment web1 -n prod -w
kubectl get pods -l app=web-frontend -n prod -w
kubectl describe deployment web1 -n prod
```

</details>

---

## ğŸ¯ Quick Command Reference

```bash
# View current deployment
kubectl -n prod get deployment web1

# Check rollout status
kubectl -n prod rollout status deployment/web1

# View rollout history
kubectl -n prod rollout history deployment/web1

# Rollback to previous version
kubectl -n prod rollout undo deployment/web1
```
